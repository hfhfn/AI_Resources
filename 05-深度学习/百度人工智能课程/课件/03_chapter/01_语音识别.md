# 3.1 百度语音识别

## 3.1.1 介绍

 百度语音识别为开发者提供业界优质且免费的语音服务，通过场景识别优化，为车载导航，智能家居和社交聊天等行业提供语音解决方案，准确率达到90%以上，让您的应用绘“声”绘色 。

## 3.1.2 服务开通

需要先开通语音识别服务应用，才能调用服务API。这里不再赘述，从创建的应用取得API Key和Secret Key。

![服务开通](images/01_创建服务.png)

## 3.1.3 两种调用方式
### 3.1.3.1 REST API介绍

百度语音识别通过 REST API 的方式给开发者提供一个通用的 HTTP 接口。 上传需要完整的录音文件，录音文件时长不超过60s。 支持普通话、英语、粤语、四川话 。

* 识别模型

  百度语音提供2种识别模型

  - 搜索模型： 效果同手机百度搜索的语音输入。适合于短语识别，没有逗号。
  - 输入法模型：效果同百度输入法的语音输入。适合于长句识别，有逗号。

  普通话搜索模型同时能识别简单的常用英语语句，效果同手机百度。

* 语音格式

  格式支持：pcm（不压缩）、wav（不压缩，pcm编码）、amr（压缩格式）。
  推荐pcm 采样率 ：16000 固定值。 编码：16bit 位深的单声道。
  百度服务端会将非pcm格式，转为pcm格式，因此使用wav、amr会有额外的转换耗时。

* 请求方式
  如果您的音频在本地，需要将音频数据放在body中。（推荐方式） 音频在本地，有JSON和raw两种方式提交。这两种提交方式，均不是浏览器表单的提交

  * json 方式，上传本地文件
    音频文件，读取二进制内容后， base64 放在speech参数内。
    音频文件的原始大小, 即二进制内容的字节数，填写“len”字段
    由于使用json格式， header为：

    Content-Type:application/json
    注意 由于base64编码后，数据会增大1/3。

  * raw方式，上传本地文件
    音频文件，读取二进制内容后，直接放在body中。
    Content-Length的值即为音频文件的大小。（一般代码会自动生成）。
    由于使用raw方式， 采样率和文件格式需要填写在Content-Type中

    Content-Type: audio/pcm;rate=16000

### 3.1.3.2 语音识别SDK API

```
AipSpeech.asr(speech, format, rate, options)
```

| 参数        | 类型   | 描述                                                         | 是否必须 |
| ----------- | ------ | ------------------------------------------------------------ | -------- |
| speech      | Buffer | 建立包含语音内容的Buffer对象, 语音文件的格式 ，pcm 或者 wav 或者 amr。不区分大小写 | 是       |
| format      | String | 包括pcm（不压缩）、wav、amr                                  | 是       |
| rate        | int    | 采样率，16000，固定值                                        | 是       |
| cuid        | String | 用户唯一标识，用来区分用户， 填写机器 MAC 地址或 IMEI 码，长度为60以内 | 否       |
| dev_pid     | Int    | 不填写lan参数生效，都不填写， 默认1537（普通话 输入法模型），dev_pid参数见本节开头的表格 | 否       |

dev_pid 参数列表

| dev_pid | 语言                       | 模型       | 是否有标点 | 备注             |
| ------- | -------------------------- | ---------- | ---------- | ---------------- |
| 1536    | 普通话(支持简单的英文识别) | 搜索模型   | 无标点     | 支持自定义词库   |
| 1537    | 普通话(纯中文识别)         | 输入法模型 | 有标点     | 不支持自定义词库 |
| 1737    | 英语                       |            | 有标点     | 不支持自定义词库 |
| 1637    | 粤语                       |            | 有标点     | 不支持自定义词库 |
| 1837    | 四川话                     |            | 有标点     | 不支持自定义词库 |
| 1936    | 普通话远场                 | 远场模型   | 有标点     | 不支持           |

**语音识别 返回数据参数详情**

| 参数    | 类型 | 是否一定输出 | 描述                                                         |
| ------- | ---- | ------------ | ------------------------------------------------------------ |
| err_no  | int  | 是           | 错误码                                                       |
| err_msg | int  | 是           | 错误码描述                                                   |
| sn      | int  | 是           | 语音数据唯一标识，系统内部产生，用于 debug                   |
| result  | int  | 是           | 识别结果数组，提供1-5 个候选结果，string 类型为识别的字符串， utf-8 编码 |

## 3.1.4 语音识别案例
安装 PyAudio

```python
pip install PyAudio
```

### 3.1.4.1 SDK实现步骤

1. 准备音频数据，或者音频文件。
2. 实例化AipSpeech
3. 填写参数，调用asr方法进行语音识别

### 3.1.4.2 实现代码

* 准备音频数据，录5秒钟的声音
  * 创建PyAudio对象
  * 定义录音参数，声道数为1（单声道），采样率16000（百度语音识别只接受16000，避免转换的必要），每个缓冲区的保存的采样数1024，录音时长为5秒
  * 调用PyAudio的open创建录音流
  * 录音
  * 结束后关闭录音流

```python
import pyaudio
import wave
import pprint
from aip import AipSpeech

# 录5秒的声音

# 创建PyAudio对象
pa = pyaudio.PyAudio()

# 录音的参数
CHANNELS=1
RATE = 16000
CHUNK = 1024
RECORD_SECONDS = 5

# 开启录音
stream = pa.open(format=pyaudio.paInt16, 
                channels=CHANNELS,
                rate=RATE, #由于百度语音之别只值16000采样,所以这里也固定为16000
                input=True,
                frames_per_buffer=CHUNK
        )

frames = []
s=input('回车开始录音:')
for i in range(0, int(RATE/CHUNK*RECORD_SECONDS + 1)):
    
    data = stream.read(CHUNK)
    frames.append(data)
print('录音结束')
    
#停止录音
stream.stop_stream()
stream.close()
pa.terminate()

# 把声音合成一个
audio_buf = b''.join(frames)
```

* 可以保存到文件
```python
# 保存到文件检查一下是否正确
waveFile = wave.open('test.wav', 'wb')
waveFile.setnchannels(CHANNELS)
waveFile.setsampwidth(pa.get_sample_size(pyaudio.paInt16))
waveFile.setframerate(RATE)
waveFile.writeframes(audio_buf)
waveFile.close() 
```


* 新建AipSpeech
  APP_ID在百度云控制台中创建，API_KEY与SECRET_KEY是在创建完毕应用后，系统分配给用户的，均为字符串，用于标识用户，为访问做签名验证，可在AI服务控制台中的应用列表中查看。


```python
from aip import AipSpeech

""" 你的 APPID AK SK """
APP_ID = '11473655'
API_KEY = 'SGbWA7P4hBXsKWCMt9Gg2ASB'
SECRET_KEY = 'd8kOxB4j08qD9bGRAmYdGCmIPXoNa4xZ'

client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)
```

* 向远程服务上传整段语音进行识别 

```python
# 读取文件
def get_file_content(filePath):
    with open(filePath, 'rb') as fp:
        return fp.read()

# 识别本地文件
results = client.asr(get_file_content('test.wav'), 'wav', 16000, {
    'dev_pid': 1536,
})
```

* 显示返回的结果

```python
pprint.pprint(redulst)


{'corpus_no': '6573535262614734646',
 'err_msg': 'success.',
 'err_no': 0,
 'result': ['一二三四五六七八九十十一十二十三十四十五十六十'],
 'sn': '729782307841530520446'}
```
