# 分组操作

- 学习目标
  - 应用groupby 进行分组,并对分组数据进行聚合,转换和过滤
  - 应用自定义函数处理分组之后的数据

## 1 聚合

- 在SQL中我们经常使用 GROUP BY 将某个字段,按不同的取值进行分组, 在pandas中也有groupby函数
- 分组之后,每组都会有至少1条数据, 将这些数据进一步处理返回单个值的过程就是聚合,比如 分组之后计算算术平均值, 或者分组之后计算频数,都属于聚合

### 1.1 单变量分组聚合

- 在之前的课程中,我们介绍了使用Gapminder数据集分组计算平均值

```python
df = pd.read_csv('data/gapminder.tsv',sep='\t')
df
```

><font color='red'>显示结果:</font>
>
>|      |     country | continent | year | lifeExp |      pop |  gdpPercap |
>| ---: | ----------: | --------: | ---: | ------: | -------: | ---------: |
>|    0 | Afghanistan |      Asia | 1952 |  28.801 |  8425333 | 779.445314 |
>|    1 | Afghanistan |      Asia | 1957 |  30.332 |  9240934 | 820.853030 |
>|    2 | Afghanistan |      Asia | 1962 |  31.997 | 10267083 | 853.100710 |
>|    3 | Afghanistan |      Asia | 1967 |  34.020 | 11537966 | 836.197138 |
>|    4 | Afghanistan |      Asia | 1972 |  36.088 | 13079460 | 739.981106 |
>|  ... |         ... |       ... |  ... |     ... |      ... |        ... |
>| 1699 |    Zimbabwe |    Africa | 1987 |  62.351 |  9216418 | 706.157306 |
>| 1700 |    Zimbabwe |    Africa | 1992 |  60.377 | 10704340 | 693.420786 |
>| 1701 |    Zimbabwe |    Africa | 1997 |  46.809 | 11404948 | 792.449960 |
>| 1702 |    Zimbabwe |    Africa | 2002 |  39.989 | 11926563 | 672.038623 |
>| 1703 |    Zimbabwe |    Africa | 2007 |  43.487 | 12311143 | 469.709298 |
>
>1704 rows × 6 columns

```python
df.groupby('year').lifeExp.mean()
```

><font color='red'>显示结果:</font>
>
>```shell
>year
>1952    49.057620
>1957    51.507401
>1962    53.609249
>1967    55.678290
>1972    57.647386
>1977    59.570157
>1982    61.533197
>1987    63.212613
>1992    64.160338
>1997    65.014676
>2002    65.694923
>2007    67.007423
>Name: lifeExp, dtype: float64
>```

- groupby语句创建了若干组,例如上面例子中, 对year字段分组, 会将数据中不同年份作为分组结果

```python
years = df.year.unique()
years
```

><font color='red'>显示结果:</font>
>
>```
>array([1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002,
>  2007], dtype=int64)
>```

- 上面groupby 之后去平均的结果,也可以手动计算

```python
# 针对1952年的数据取子集
y1952 = df.loc[df.year==1952,:]
y1952
```

><font color='red'>显示结果:</font>
>
>|      |            country | continent | year | lifeExp |      pop |   gdpPercap |
>| ---: | -----------------: | --------: | ---: | ------: | -------: | ----------: |
>|    0 |        Afghanistan |      Asia | 1952 |  28.801 |  8425333 |  779.445314 |
>|   12 |            Albania |    Europe | 1952 |  55.230 |  1282697 | 1601.056136 |
>|   24 |            Algeria |    Africa | 1952 |  43.077 |  9279525 | 2449.008185 |
>|   36 |             Angola |    Africa | 1952 |  30.015 |  4232095 | 3520.610273 |
>|   48 |          Argentina |  Americas | 1952 |  62.485 | 17876956 | 5911.315053 |
>|  ... |                ... |       ... |  ... |     ... |      ... |         ... |
>| 1644 |            Vietnam |      Asia | 1952 |  40.412 | 26246839 |  605.066492 |
>| 1656 | West Bank and Gaza |      Asia | 1952 |  43.160 |  1030585 | 1515.592329 |
>| 1668 |        Yemen, Rep. |      Asia | 1952 |  32.548 |  4963829 |  781.717576 |
>| 1680 |             Zambia |    Africa | 1952 |  42.038 |  2672000 | 1147.388831 |
>| 1692 |           Zimbabwe |    Africa | 1952 |  48.451 |  3080907 |  406.884115 |
>
>142 rows × 6 columns

```python
y1952.lifeExp.mean()
```

><font color='red'>显示结果:</font>
>
>```shell
>49.05761971830987
>```

- groupby 语句会针对每个不同年份重复上述过程,并把所有结果放入一个DataFrame中返回
- mean函数不是唯一的聚合函数, Pandas内置了许多方法, 都可以与groupby语句搭配使用

### 1.2 Pandas内置的聚合方法

- 可以与groupby一起使用的方法和函数

| Pandas方法 | Numpy函数        | 说明                                         |
| ---------- | ---------------- | -------------------------------------------- |
| count      | np.count_nonzero | 频率统计(不包含NaN值)                        |
| size       |                  | 频率统计(包含NaN值)                          |
| mean       | np.mean          | 求平均值                                     |
| std        | np.std           | 标准差                                       |
| min        | np.min           | 最小值                                       |
| quantile() | np.percentile()  | 分位数                                       |
| max        | np.max           | 求最大值                                     |
| sum        | np.sum           | 求和                                         |
| var        | np.var           | 方差                                         |
| describe   |                  | 计数、平均值、标准差，最小值、分位数、最大值 |
| first      |                  | 返回第一行                                   |
| last       |                  | 返回最后一行                                 |
| nth        |                  | 返回第N行(Python从0开始计数)                 |

- 上面的结果是分组之后取平均, 也可以使用describe函数同时计算多个统计量

```python
df.groupby('continent').lifeExp.describe()
```

><font color='red'>显示结果:</font>
>
>| continent | count |      mean |       std |    min |      25% |     50% |      75% |    max |
>| --------: | ----: | --------: | --------: | -----: | -------: | ------: | -------: | -----: |
>|    Africa | 624.0 | 48.865330 |  9.150210 | 23.599 | 42.37250 | 47.7920 | 54.41150 | 76.442 |
>|  Americas | 300.0 | 64.658737 |  9.345088 | 37.579 | 58.41000 | 67.0480 | 71.69950 | 80.653 |
>|      Asia | 396.0 | 60.064903 | 11.864532 | 28.801 | 51.42625 | 61.7915 | 69.50525 | 82.603 |
>|    Europe | 360.0 | 71.903686 |  5.433178 | 43.585 | 69.57000 | 72.2410 | 75.45050 | 81.757 |
>|   Oceania |  24.0 | 74.326208 |  3.795611 | 69.120 | 71.20500 | 73.6650 | 77.55250 | 81.235 |

### 1.3 聚合函数

#### 其他库的函数

- 可以使用Numpy库的mean函数

```python
import numpy as np
df.groupby('continent').lifeExp.agg(np.mean)
```

><font color='red'>显示结果:</font>
>
>```shell
>continent
>Africa      48.865330
>Americas    64.658737
>Asia        60.064903
>Europe      71.903686
>Oceania     74.326208
>Name: lifeExp, dtype: float64
>```

- agg和 aggregate效果一样

```python
df.groupby('continent').lifeExp.aggregate(np.mean)
```

><font color='red'>显示结果:</font>
>
>```shell
>continent
>Africa      48.865330
>Americas    64.658737
>Asia        60.064903
>Europe      71.903686
>Oceania     74.326208
>Name: lifeExp, dtype: float64
>```

#### 自定义函数

- 如果想在聚合的时候,使用非Pandas或其他库提供的计算, 可以自定义函数,然后再aggregate中调用它

```python
def my_mean(values):
    '''计算平均值
    '''
    n = len(values) # 获取数据条目数
    sum = 0
    for value in values:
        sum += value
    return(sum/n)
# 调用自定义函数
df.groupby('year').lifeExp.agg(my_mean)
```

><font color='red'>显示结果:</font>
>
>```shell
>year
>1952    49.057620
>1957    51.507401
>1962    53.609249
>1967    55.678290
>1972    57.647386
>1977    59.570157
>1982    61.533197
>1987    63.212613
>1992    64.160338
>1997    65.014676
>2002    65.694923
>2007    67.007423
>Name: lifeExp, dtype: float64
>```

- 自定义函数中只有一个参数values, 但传入该函数中的数据是一组值, 需要对values进行迭代才能取出每一个值
- 自定义函数可以有多个参数, 第一个参数接受来自DataFrame分组这之后的值, 其余参数可自定义

```python
# 计算全球平均预期寿命的平均值 与分组之后的平均值做差
def my_mean_diff(values,diff_value):
    '''计算平均值和diff_value之差
    '''
    n = len(values)
    sum = 0
    for value in values:
        sum+=value
    mean = sum/n
    return(mean-diff_value)
# 计算整个数据集的平均年龄
global_mean = df.lifeExp.mean()
# 调用自定义函数 计算平均值的差值
df.groupby('year').lifeExp.agg(my_mean_diff,diff_value = global_mean)
```

><font color='red'>显示结果:</font>
>
>```shell
>year
>1952   -10.416820
>1957    -7.967038
>1962    -5.865190
>1967    -3.796150
>1972    -1.827053
>1977     0.095718
>1982     2.058758
>1987     3.738173
>1992     4.685899
>1997     5.540237
>2002     6.220483
>2007     7.532983
>Name: lifeExp, dtype: float64
>```

### 1.4 同时传入多个函数

- 分组之后想计算多个聚合函数,可以把它们全部放入一个Python列表,然后把整个列表传入agg或aggregate中

```python
# 按年计算lifeExp 的非零个数,平均值和标准差
df.groupby('year').lifeExp.agg([np.count_nonzero,np.mean,np.std])
```

><font color='red'>显示结果:</font>
>
>|      | count_nonzero |      mean |       std |
>| ---: | ------------: | --------: | --------: |
>| year |               |           |           |
>| 1952 |         142.0 | 49.057620 | 12.225956 |
>| 1957 |         142.0 | 51.507401 | 12.231286 |
>| 1962 |         142.0 | 53.609249 | 12.097245 |
>| 1967 |         142.0 | 55.678290 | 11.718858 |
>| 1972 |         142.0 | 57.647386 | 11.381953 |
>| 1977 |         142.0 | 59.570157 | 11.227229 |
>| 1982 |         142.0 | 61.533197 | 10.770618 |
>| 1987 |         142.0 | 63.212613 | 10.556285 |
>| 1992 |         142.0 | 64.160338 | 11.227380 |
>| 1997 |         142.0 | 65.014676 | 11.559439 |
>| 2002 |         142.0 | 65.694923 | 12.279823 |
>| 2007 |         142.0 | 67.007423 | 12.073021 |

### 1.5 向agg/aggregate中传入字典

- 分组之后,可以对多个字段用不同的方式聚合

```python
df.groupby('year').agg({'lifeExp':'mean','pop':'median','gdpPercap':'median'})
```

><font color='red'>显示结果:</font>
>
>|      |   lifeExp |        pop |   gdpPercap |
>| ---: | --------: | ---------: | ----------: |
>| year |           |            |             |
>| 1952 | 49.057620 |  3943953.0 | 1968.528344 |
>| 1957 | 51.507401 |  4282942.0 | 2173.220291 |
>| 1962 | 53.609249 |  4686039.5 | 2335.439533 |
>| 1967 | 55.678290 |  5170175.5 | 2678.334741 |
>| 1972 | 57.647386 |  5877996.5 | 3339.129407 |
>| 1977 | 59.570157 |  6404036.5 | 3798.609244 |
>| 1982 | 61.533197 |  7007320.0 | 4216.228428 |
>| 1987 | 63.212613 |  7774861.5 | 4280.300366 |
>| 1992 | 64.160338 |  8688686.5 | 4386.085502 |
>| 1997 | 65.014676 |  9735063.5 | 4781.825478 |
>| 2002 | 65.694923 | 10372918.5 | 5319.804524 |
>| 2007 | 67.007423 | 10517531.0 | 6124.371109 |

- 从聚合之后返回的DataFrame中发现, 聚合后的列名就是聚合函数的名字, 可以通过rename进行重命名

```python
df.groupby('year').agg({'lifeExp':'mean','pop':'median','gdpPercap':'median'}).\
    rename(columns={'lifeExp':'平均寿命','pop':'人口','gdpPercap':'人均Gdp'}).reset_index()
```

><font color='red'>显示结果:</font>
>
>|      | year |  平均寿命 |       人口 |     人均Gdp |
>| ---: | ---: | --------: | ---------: | ----------: |
>|    0 | 1952 | 49.057620 |  3943953.0 | 1968.528344 |
>|    1 | 1957 | 51.507401 |  4282942.0 | 2173.220291 |
>|    2 | 1962 | 53.609249 |  4686039.5 | 2335.439533 |
>|    3 | 1967 | 55.678290 |  5170175.5 | 2678.334741 |
>|    4 | 1972 | 57.647386 |  5877996.5 | 3339.129407 |
>|    5 | 1977 | 59.570157 |  6404036.5 | 3798.609244 |
>|    6 | 1982 | 61.533197 |  7007320.0 | 4216.228428 |
>|    7 | 1987 | 63.212613 |  7774861.5 | 4280.300366 |
>|    8 | 1992 | 64.160338 |  8688686.5 | 4386.085502 |
>|    9 | 1997 | 65.014676 |  9735063.5 | 4781.825478 |
>|   10 | 2002 | 65.694923 | 10372918.5 | 5319.804524 |
>|   11 | 2007 | 67.007423 | 10517531.0 | 6124.371109 |

## 2 转换

- transform 转换，需要把DataFrame中的值传递给一个函数， 而后由该函数"转换"数据。
- aggregate(聚合) 返回单个聚合值，但transform 不会减少数据量

### 使用transform分组计算z分数

```python
# 计算z-score   x - 平均值/标准差
def my_zscore(x):
    return (x-x.mean())/x.std()
#按年分组 计算z-score
df.groupby('year').lifeExp.transform(my_zscore)
```

><font color='red'>显示结果:</font>
>
>```shell
>0      -1.656854
>1      -1.731249
>2      -1.786543
>3      -1.848157
>4      -1.894173
>          ...   
>1699   -0.081621
>1700   -0.336974
>1701   -1.574962
>1702   -2.093346
>1703   -1.948180
>Name: lifeExp, Length: 1704, dtype: float64
>```

```python
# 查看数据集条目数， 跟之前transform处理之后的条目数一样
df.shape
```

><font color='red'>显示结果:</font>
>
>```shell
>(1704, 6)
>```

### transform分组填充缺失值

- 之前介绍了填充缺失值的各种方法，对于某些数据集，可以使用列的平均值来填充缺失值。某些情况下，可以考虑将列进行分组，分组之后取平均再填充缺失值

```python
tips_10 = pd.read_csv('data/tips.csv').sample(10,random_state = 42)
tips_10
```

><font color='red'>显示结果:</font>
>
>|      | total_bill |  tip |    sex | smoker |  day |   time | size |
>| ---: | ---------: | ---: | -----: | -----: | ---: | -----: | ---: |
>|   24 |      19.82 | 3.18 |   Male |     No |  Sat | Dinner |    2 |
>|    6 |       8.77 | 2.00 |   Male |     No |  Sun | Dinner |    2 |
>|  153 |      24.55 | 2.00 |   Male |     No |  Sun | Dinner |    4 |
>|  211 |      25.89 | 5.16 |   Male |    Yes |  Sat | Dinner |    4 |
>|  198 |      13.00 | 2.00 | Female |    Yes | Thur |  Lunch |    2 |
>|  176 |      17.89 | 2.00 |   Male |    Yes |  Sun | Dinner |    2 |
>|  192 |      28.44 | 2.56 |   Male |    Yes | Thur |  Lunch |    2 |
>|  124 |      12.48 | 2.52 | Female |     No | Thur |  Lunch |    2 |
>|    9 |      14.78 | 3.23 |   Male |     No |  Sun | Dinner |    2 |
>|  101 |      15.38 | 3.00 | Female |    Yes |  Fri | Dinner |    2 |

- 构建缺失值

```python
#np.random.permutation 将序列乱序
tips_10.loc[np.random.permutation(tips_10.index)[:4],'total_bill'] = np.NaN
tips_10
```

><font color='red'>显示结果:</font>
>
>|      | total_bill |  tip |    sex | smoker |  day |   time | size |
>| ---: | ---------: | ---: | -----: | -----: | ---: | -----: | ---: |
>|   24 |      19.82 | 3.18 |   Male |     No |  Sat | Dinner |    2 |
>|    6 |       8.77 | 2.00 |   Male |     No |  Sun | Dinner |    2 |
>|  153 |        NaN | 2.00 |   Male |     No |  Sun | Dinner |    4 |
>|  211 |        NaN | 5.16 |   Male |    Yes |  Sat | Dinner |    4 |
>|  198 |        NaN | 2.00 | Female |    Yes | Thur |  Lunch |    2 |
>|  176 |        NaN | 2.00 |   Male |    Yes |  Sun | Dinner |    2 |
>|  192 |      28.44 | 2.56 |   Male |    Yes | Thur |  Lunch |    2 |
>|  124 |      12.48 | 2.52 | Female |     No | Thur |  Lunch |    2 |
>|    9 |      14.78 | 3.23 |   Male |     No |  Sun | Dinner |    2 |
>|  101 |      15.38 | 3.00 | Female |    Yes |  Fri | Dinner |    2 |

- 查看缺失情况

```python
count_sex = tips_10.groupby('sex').count()
count_sex
```

><font color='red'>显示结果:</font>
>
>|    sex | total_bill |  tip | smoker |  day | time | size |
>| -----: | ---------: | ---: | -----: | ---: | ---: | ---: |
>| Female |          2 |    3 |      3 |    3 |    3 |    3 |
>|   Male |          4 |    7 |      7 |    7 |    7 |    7 |

- 定义函数填充缺失值

```python
def fill_na_mean(x):
    # 求平均
    avg = x.mean()
    # 填充缺失值
    return(x.fillna(avg))
total_bill_group_mean = tips_10.groupby('sex').total_bill.transform(fill_na_mean)
total_bill_group_mean
```

><font color='red'>显示结果:</font>
>
>```
>24     19.8200
>6       8.7700
>153    17.9525
>211    17.9525
>198    13.9300
>176    17.9525
>192    28.4400
>124    12.4800
>9      14.7800
>101    15.3800
>Name: total_bill, dtype: float64
>```

- 将计算的结果赋值新列

```python
tips_10['fill_total_bill'] = total_bill_group_mean
tips_10
```

><font color='red'>显示结果:</font>
>
>|      | total_bill |  tip |    sex | smoker |  day |   time | size | fill_total_bill |
>| ---: | ---------: | ---: | -----: | -----: | ---: | -----: | ---: | --------------: |
>|   24 |      19.82 | 3.18 |   Male |     No |  Sat | Dinner |    2 |         19.8200 |
>|    6 |       8.77 | 2.00 |   Male |     No |  Sun | Dinner |    2 |          8.7700 |
>|  153 |        NaN | 2.00 |   Male |     No |  Sun | Dinner |    4 |         17.9525 |
>|  211 |        NaN | 5.16 |   Male |    Yes |  Sat | Dinner |    4 |         17.9525 |
>|  198 |        NaN | 2.00 | Female |    Yes | Thur |  Lunch |    2 |         13.9300 |
>|  176 |        NaN | 2.00 |   Male |    Yes |  Sun | Dinner |    2 |         17.9525 |
>|  192 |      28.44 | 2.56 |   Male |    Yes | Thur |  Lunch |    2 |         28.4400 |
>|  124 |      12.48 | 2.52 | Female |     No | Thur |  Lunch |    2 |         12.4800 |
>|    9 |      14.78 | 3.23 |   Male |     No |  Sun | Dinner |    2 |         14.7800 |
>|  101 |      15.38 | 3.00 | Female |    Yes |  Fri | Dinner |    2 |         15.3800 |

- 对比total_bill 和 fill_total_bill 发现 Male 和 Female 的填充值不同

### transform练习

- weight_loss数据集，找到减肥比赛赢家

```python
# 加载数据
weight_loss = pd.read_csv('data/weight_loss.csv')
#查看数据
weight_loss
```

><font color='red'>显示结果:</font>
>
>|      | Name | Month |   Week | Weight |
>| ---: | ---: | ----: | -----: | -----: |
>|    0 |  Bob |   Jan | Week 1 |    291 |
>|    1 |  Amy |   Jan | Week 1 |    197 |
>|    2 |  Bob |   Jan | Week 2 |    288 |
>|    3 |  Amy |   Jan | Week 2 |    189 |
>|    4 |  Bob |   Jan | Week 3 |    283 |
>|    5 |  Amy |   Jan | Week 3 |    189 |
>|    6 |  Bob |   Jan | Week 4 |    283 |
>|    7 |  Amy |   Jan | Week 4 |    190 |
>|    8 |  Bob |   Feb | Week 1 |    283 |
>|    9 |  Amy |   Feb | Week 1 |    190 |
>|   10 |  Bob |   Feb | Week 2 |    275 |
>|   11 |  Amy |   Feb | Week 2 |    184 |
>|   12 |  Bob |   Feb | Week 3 |    268 |
>|   13 |  Amy |   Feb | Week 3 |    177 |
>|   14 |  Bob |   Feb | Week 4 |    268 |
>|   15 |  Amy |   Feb | Week 4 |    173 |
>|   16 |  Bob |   Mar | Week 1 |    268 |
>|   17 |  Amy |   Mar | Week 1 |    173 |
>|   18 |  Bob |   Mar | Week 2 |    271 |
>|   19 |  Amy |   Mar | Week 2 |    173 |
>|   20 |  Bob |   Mar | Week 3 |    265 |
>|   21 |  Amy |   Mar | Week 3 |    170 |
>|   22 |  Bob |   Mar | Week 4 |    261 |
>|   23 |  Amy |   Mar | Week 4 |    170 |
>|   24 |  Bob |   Apr | Week 1 |    261 |
>|   25 |  Amy |   Apr | Week 1 |    170 |
>|   26 |  Bob |   Apr | Week 2 |    258 |
>|   27 |  Amy |   Apr | Week 2 |    164 |
>|   28 |  Bob |   Apr | Week 3 |    253 |
>|   29 |  Amy |   Apr | Week 3 |    164 |
>|   30 |  Bob |   Apr | Week 4 |    250 |
>|   31 |  Amy |   Apr | Week 4 |    161 |

- Bob，Amy两个人的减肥记录，从1月到4月

```python
# 只查看1月份数据  query 类似SQL的where条件
weight_loss.query('Month == "Jan"')
```

><font color='red'>显示结果:</font>
>
>|      | Name | Month |   Week | Weight |
>| ---: | ---: | ----: | -----: | -----: |
>|    0 |  Bob |   Jan | Week 1 |    291 |
>|    1 |  Amy |   Jan | Week 1 |    197 |
>|    2 |  Bob |   Jan | Week 2 |    288 |
>|    3 |  Amy |   Jan | Week 2 |    189 |
>|    4 |  Bob |   Jan | Week 3 |    283 |
>|    5 |  Amy |   Jan | Week 3 |    189 |
>|    6 |  Bob |   Jan | Week 4 |    283 |
>|    7 |  Amy |   Jan | Week 4 |    190 |

- 定义函数计算每周减肥比例 并测试

```python
def find_perc_loss(s):
    return abs((s - s.iloc[0]) / s.iloc[0])
#查找Bob 1月份的数据
bob_jan = weight_loss.query('Name=="Bob" and Month=="Jan"')
#测试计算减肥比例的方法
find_perc_loss(bob_jan['Weight'])
```

><font color='red'>显示结果:</font>
>
>```shell
>0    0.000000
>2    0.010309
>4    0.027491
>6    0.027491
>Name: Weight, dtype: float64
>```

- 计算每周减肥比例

```python
pcnt_loss = weight_loss.groupby(['Name', 'Month'])['Weight'].transform(find_perc_loss)
pcnt_loss.head(8)
```

><font color='red'>显示结果:</font>
>
>```shell
>0    0.000000
>1    0.000000
>2    0.010309
>3    0.040609
>4    0.027491
>5    0.040609
>6    0.027491
>7    0.035533
>Name: Weight, dtype: float64
>```

```python
weight_loss['Perc Weight Loss'] = pcnt_loss.round(3)
# 查找每个月最后一周的数据 用来比较减肥效果
week4 = weight_loss.query('Week == "Week 4"')
week4
```

><font color='red'>显示结果:</font>
>
>|      | Name | Month |   Week | Weight | Perc Weight Loss |
>| ---: | ---: | ----: | -----: | -----: | ---------------: |
>|    6 |  Bob |   Jan | Week 4 |    283 |            0.027 |
>|    7 |  Amy |   Jan | Week 4 |    190 |            0.036 |
>|   14 |  Bob |   Feb | Week 4 |    268 |            0.053 |
>|   15 |  Amy |   Feb | Week 4 |    173 |            0.089 |
>|   22 |  Bob |   Mar | Week 4 |    261 |            0.026 |
>|   23 |  Amy |   Mar | Week 4 |    170 |            0.017 |
>|   30 |  Bob |   Apr | Week 4 |    250 |            0.042 |
>|   31 |  Amy |   Apr | Week 4 |    161 |            0.053 |

- 在第四周数据基础上，找到 Bob 和 Amy的减肥数据

```python
week4_Bob = week4.query('Name == "Bob"')[['Month','Perc Weight Loss']]
week4_Bob
```

><font color='red'>显示结果:</font>
>
>|      | Month | Perc Weight Loss |
>| ---: | ----: | ---------------: |
>|    6 |   Jan |            0.027 |
>|   14 |   Feb |            0.053 |
>|   22 |   Mar |            0.026 |
>|   30 |   Apr |            0.042 |

```python
week4_Amy = week4.query('Name == "Amy"')[['Month','Perc Weight Loss']]
week4_Amy
```

><font color='red'>显示结果:</font>
>
>|      | Month | Perc Weight Loss |
>| ---: | ----: | ---------------: |
>|    7 |   Jan |            0.036 |
>|   15 |   Feb |            0.089 |
>|   23 |   Mar |            0.017 |
>|   31 |   Apr |            0.053 |

- 比较Bob 和 Amy的减肥效果, Amy的减肥效果更明显

```python
week4_Bob.set_index('Month')-week4_Amy.set_index('Month')
```

><font color='red'>显示结果:</font>
>
>| Month | Perc Weight Loss |
>| ----: | ---------------: |
>|   Jan |           -0.009 |
>|   Feb |           -0.036 |
>|   Mar |            0.009 |
>|   Apr |           -0.011 |

## 3 过滤

- 使用groupby方法还可以过滤数据，调用filter 方法，传入一个返回布尔值的函数，返回False的数据会被过滤掉
- 使用之前的小费数据

```python
tips = pd.read_csv('data/tips.csv')
# 查看用餐人数
tips['size'].value_counts()
```

><font color='red'>显示结果:</font>
>
>```
>2    156
>3     38
>4     37
>5      5
>6      4
>1      4
>Name: size, dtype: int64
>```

- 结果显示，人数为1、5和6人的数据比较少，考虑将这部分数据过滤掉

```python
tips_filtered = tips.groupby('size').filter(lambda x: x['size'].count()>30)
tips_filtered
```

><font color='red'>显示结果:</font>
>
>|      | total_bill |  tip |    sex | smoker |  day |   time | size |
>| ---: | ---------: | ---: | -----: | -----: | ---: | -----: | ---: |
>|    0 |      16.99 | 1.01 | Female |     No |  Sun | Dinner |    2 |
>|    1 |      10.34 | 1.66 |   Male |     No |  Sun | Dinner |    3 |
>|    2 |      21.01 | 3.50 |   Male |     No |  Sun | Dinner |    3 |
>|    3 |      23.68 | 3.31 |   Male |     No |  Sun | Dinner |    2 |
>|    4 |      24.59 | 3.61 | Female |     No |  Sun | Dinner |    4 |
>|  ... |        ... |  ... |    ... |    ... |  ... |    ... |  ... |
>|  239 |      29.03 | 5.92 |   Male |     No |  Sat | Dinner |    3 |
>|  240 |      27.18 | 2.00 | Female |    Yes |  Sat | Dinner |    2 |
>|  241 |      22.67 | 2.00 |   Male |    Yes |  Sat | Dinner |    2 |
>|  242 |      17.82 | 1.75 |   Male |     No |  Sat | Dinner |    2 |
>|  243 |      18.78 | 3.00 | Female |     No | Thur | Dinner |    2 |

- 查看结果

```python
tips_filtered['size'].value_counts()
```

><font color='red'>显示结果:</font>
>
>```
>2    156
>3     38
>4     37
>Name: size, dtype: int64
>```

## 4 DataFrameGroupBy对象

### 4.1 分组

- 准备数据

```python
tips_10 = pd.read_csv('data/tips.csv').sample(10,random_state = 42)
tips_10
```

><font color='red'>显示结果:</font>
>
>|      | total_bill |  tip |    sex | smoker |  day |   time | size |
>| ---: | ---------: | ---: | -----: | -----: | ---: | -----: | ---: |
>|   24 |      19.82 | 3.18 |   Male |     No |  Sat | Dinner |    2 |
>|    6 |       8.77 | 2.00 |   Male |     No |  Sun | Dinner |    2 |
>|  153 |      24.55 | 2.00 |   Male |     No |  Sun | Dinner |    4 |
>|  211 |      25.89 | 5.16 |   Male |    Yes |  Sat | Dinner |    4 |
>|  198 |      13.00 | 2.00 | Female |    Yes | Thur |  Lunch |    2 |
>|  176 |      17.89 | 2.00 |   Male |    Yes |  Sun | Dinner |    2 |
>|  192 |      28.44 | 2.56 |   Male |    Yes | Thur |  Lunch |    2 |
>|  124 |      12.48 | 2.52 | Female |     No | Thur |  Lunch |    2 |
>|    9 |      14.78 | 3.23 |   Male |     No |  Sun | Dinner |    2 |
>|  101 |      15.38 | 3.00 | Female |    Yes |  Fri | Dinner |    2 |

```python
# 调用groupby 创建分组对象
grouped = tips_10.groupby('sex')
grouped
```

><font color='red'>显示结果:</font>
>
>```shell
><pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000020591F63CF8>
>```

- grouped是一个DataFrameGroupBy对象，如果想查看计算过的分组，可以借助groups属性实现

```python
grouped.groups
```

><font color='red'>显示结果:</font>
>
>```shell
>{'Female': [198, 124, 101], 'Male': [24, 6, 153, 211, 176, 192, 9]}
>```

- 上面返回的结果是DataFrame的索引，实际上就是原始数据的行数
- 在DataFrameGroupBy对象基础上，直接就可以进行aggregate,transform计算了

```python
grouped.mean()
```

><font color='red'>显示结果:</font>
>
>|    sex | total_bill |      tip |     size |
>| -----: | ---------: | -------: | -------: |
>| Female |      13.62 | 2.506667 | 2.000000 |
>|   Male |      20.02 | 2.875714 | 2.571429 |

- 上面结果直接计算了按sex分组后，所有列的平均值，但只返回了数值列的结果，非数值列不会计算平均值

- 通过get_group选择分组

```python
female = grouped.get_group('Female')
female
```

><font color='red'>显示结果:</font>
>
>|      | total_bill |  tip |    sex | smoker |  day |   time | size |
>| ---: | ---------: | ---: | -----: | -----: | ---: | -----: | ---: |
>|  198 |      13.00 | 2.00 | Female |    Yes | Thur |  Lunch |    2 |
>|  124 |      12.48 | 2.52 | Female |     No | Thur |  Lunch |    2 |
>|  101 |      15.38 | 3.00 | Female |    Yes |  Fri | Dinner |    2 |

### 4.2 遍历分组

- 通过groupby对象，可以遍历所有分组，相比于在groupby之后使用aggregate、transform和filter，有时候使用for循环解决问题更简单

```python
for sex_group in grouped:
    print(sex_group)
```

><font color='red'>显示结果:</font>
>
>```shell
>('Female',      total_bill   tip     sex smoker   day    time  size
>198       13.00  2.00  Female    Yes  Thur   Lunch     2
>124       12.48  2.52  Female     No  Thur   Lunch     2
>101       15.38  3.00  Female    Yes   Fri  Dinner     2)
>('Male',      total_bill   tip   sex smoker   day    time  size
>24        19.82  3.18  Male     No   Sat  Dinner     2
>6          8.77  2.00  Male     No   Sun  Dinner     2
>153       24.55  2.00  Male     No   Sun  Dinner     4
>211       25.89  5.16  Male    Yes   Sat  Dinner     4
>176       17.89  2.00  Male    Yes   Sun  Dinner     2
>192       28.44  2.56  Male    Yes  Thur   Lunch     2
>9         14.78  3.23  Male     No   Sun  Dinner     2)
>```

- DataFrameGroupBy对象直接传入索引，会报错

```python
grouped[0]
```

><font color='red'>显示结果:</font>
>
>```shell
>---------------------------------------------------------------------------
>KeyError                                  Traceback (most recent call last)
><ipython-input-75-2ce84a56ac6b> in <module>()
>----> 1 grouped[0]
>
>e:\python\data\lib\site-packages\pandas\core\groupby\generic.py in __getitem__(self, key)
>   1642                 stacklevel=2,
>   1643             )
>-> 1644         return super().__getitem__(key)
>   1645 
>   1646     def _gotitem(self, key, ndim: int, subset=None):
>
>e:\python\data\lib\site-packages\pandas\core\base.py in __getitem__(self, key)
>    226         else:
>    227             if key not in self.obj:
>--> 228                 raise KeyError(f"Column not found: {key}")
>    229             return self._gotitem(key, ndim=1)
>    230 
>
>KeyError: 'Column not found: 0'
>```

```python
for sex_group in grouped:
    #遍历grouped对象，查看sex_group数据类型
    print(type(sex_group))
    # 查看元素个数
    print(len(sex_group))
    # 查看第一个元素
    print(sex_group[0])
    # 查看第一个元素数据类型
    print(type(sex_group[0]))
    # 查看第二个元素
    print(sex_group[1])
    # 查看第二个元素数据类型
    print(type(sex_group[1]))
    break
```

><font color='red'>显示结果:</font>
>
>```shell
><class 'tuple'>
>2
>Female
><class 'str'>
>     total_bill   tip     sex smoker   day    time  size
>198       13.00  2.00  Female    Yes  Thur   Lunch     2
>124       12.48  2.52  Female     No  Thur   Lunch     2
>101       15.38  3.00  Female    Yes   Fri  Dinner     2
><class 'pandas.core.frame.DataFrame'>
>```

### 4.3 多个分组

- 前面使用的groupby语句只包含一个变量，可以在groupby中添加多个变量
- 比如上面用到的消费数据集，可以使用groupby按性别和用餐时间分别计算小费数据的平均值

```python
group_avg = tips_10.groupby(['sex','time']).mean()
group_avg
```

><font color='red'>显示结果:</font>
>
>|        |        | total_bill |      tip |     size |
>| -----: | -----: | ---------: | -------: | -------: |
>|    sex |   time |            |          |          |
>| Female | Dinner |  15.380000 | 3.000000 | 2.000000 |
>|        |  Lunch |  12.740000 | 2.260000 | 2.000000 |
>|   Male | Dinner |  18.616667 | 2.928333 | 2.666667 |
>|        |  Lunch |  28.440000 | 2.560000 | 2.000000 |

- 分别查看分组之后结果的列名和行索引

```python
group_avg.columns
```

><font color='red'>显示结果:</font>
>
>```shell
>Index(['total_bill', 'tip', 'size'], dtype='object')
>```

```python
group_avg.index
```

><font color='red'>显示结果:</font>
>
>```shell
>MultiIndex([('Female', 'Dinner'),
>            ('Female',  'Lunch'),
>            (  'Male', 'Dinner'),
>            (  'Male',  'Lunch')],
>           names=['sex', 'time'])
>```

- 可以看到，多个分组之后返回的是MultiIndex，如果想得到一个普通的DataFrame，可以在结果上调用reset_index方法

```python
group_avg.reset_index()
```

><font color='red'>显示结果:</font>
>
>|      |    sex |   time | total_bill |      tip |     size |
>| ---: | -----: | -----: | ---------: | -------: | -------: |
>|    0 | Female | Dinner |  15.380000 | 3.000000 | 2.000000 |
>|    1 | Female |  Lunch |  12.740000 | 2.260000 | 2.000000 |
>|    2 |   Male | Dinner |  18.616667 | 2.928333 | 2.666667 |
>|    3 |   Male |  Lunch |  28.440000 | 2.560000 | 2.000000 |

- 也可以在分组的时候通过as_index = False参数（默认是True），效果与调用reset_index()一样

```python
 tips_10.groupby(['sex','time'],as_index = False).mean()
```

><font color='red'>显示结果:</font>
>
>|      |    sex |   time | total_bill |      tip |     size |
>| ---: | -----: | -----: | ---------: | -------: | -------: |
>|    0 | Female | Dinner |  15.380000 | 3.000000 | 2.000000 |
>|    1 | Female |  Lunch |  12.740000 | 2.260000 | 2.000000 |
>|    2 |   Male | Dinner |  18.616667 | 2.928333 | 2.666667 |
>|    3 |   Male |  Lunch |  28.440000 | 2.560000 | 2.000000 |

## 小结

- 分组是数据分析中常见的操作，有助于从不同角度观察数据
- 分组之后可以得到DataFrameGroupby对象，该对象可以进行聚合、转换、过滤操作
- 分组之后的数据处理可以使用已有的内置函数，也可以使用自定义函数
- 分组不但可以对单个字段进行分组，也可以对多个字段进行分组，多个字段分组之后可以得到MultiIndex数据，可以通过reset_index方法将数据变成普通的DataFrame